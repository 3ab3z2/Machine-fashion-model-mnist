{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including NumPy, pandas, scikit-learn, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Transform Data\n",
    "Load the Fashion-MNIST dataset from the ubyte files and transform it into a format suitable for saving as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Transform Data\n",
    "\n",
    "# Function to load ubyte files\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte')\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Load training and test data\n",
    "train_images, train_labels = load_mnist('', kind='train')\n",
    "test_images, test_labels = load_mnist('', kind='t10k')\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_images)\n",
    "train_df.insert(0, 'label', train_labels)\n",
    "\n",
    "test_df = pd.DataFrame(test_images)\n",
    "test_df.insert(0, 'label', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data to CSV Files\n",
    "Save the transformed training and test datasets to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Data to CSV Files\n",
    "\n",
    "# Save the transformed training dataset to a CSV file\n",
    "train_df.to_csv('fashion_mnist_train.csv', index=False)\n",
    "\n",
    "# Save the transformed test dataset to a CSV file\n",
    "test_df.to_csv('fashion_mnist_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data from CSV Files\n",
    "Load the training and test datasets from the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from CSV Files\n",
    "\n",
    "# Load the training dataset from the CSV file\n",
    "train_df = pd.read_csv('fashion_mnist_train.csv')\n",
    "\n",
    "# Load the test dataset from the CSV file\n",
    "test_df = pd.read_csv('fashion_mnist_test.csv')\n",
    "\n",
    "# Separate features and labels for training data\n",
    "X_train = train_df.drop(columns=['label'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "# Separate features and labels for test data\n",
    "X_test = test_df.drop(columns=['label'])\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Regression Model\n",
    "Train a logistic regression model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression Model\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the training and test data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the scaled training data\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the scaled test data\n",
    "y_pred_logistic = logistic_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_logistic = logistic_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "# Generate classification report\n",
    "class_report_logistic = classification_report(y_test, y_pred_logistic)\n",
    "\n",
    "# Generate ROC curve and AUC\n",
    "y_prob_logistic = logistic_model.predict_proba(X_test_scaled)\n",
    "fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_prob_logistic[:, 1], pos_label=1)\n",
    "roc_auc_logistic = auc(fpr_logistic, tpr_logistic)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print('Classification Report:')\n",
    "print(class_report_logistic)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.matshow(conf_matrix_logistic, cmap='coolwarm', fignum=1)\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train K-Nearest Neighbors Model\n",
    "Train a K-Nearest Neighbors (KNN) model on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Nearest Neighbors Model\n",
    "\n",
    "# Initialize the K-Nearest Neighbors model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model on the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_knn = knn_model.score(X_test, y_test)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Generate classification report\n",
    "class_report_knn = classification_report(y_test, y_pred_knn)\n",
    "\n",
    "# Generate ROC curve and AUC\n",
    "y_prob_knn = knn_model.predict_proba(X_test)\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test, y_prob_knn[:, 1], pos_label=1)\n",
    "roc_auc_knn = auc(fpr_knn, tpr_knn)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(f'K-Nearest Neighbors Accuracy: {accuracy_knn}')\n",
    "print('Classification Report:')\n",
    "print(class_report_knn)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.matshow(conf_matrix_knn, cmap='coolwarm', fignum=1)\n",
    "plt.title('Confusion Matrix - K-Nearest Neighbors')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_knn, tpr_knn, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - K-Nearest Neighbors')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models\n",
    "Evaluate the performance of the trained models using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "\n",
    "# Compare Logistic Regression and K-Nearest Neighbors\n",
    "\n",
    "# Print comparison of accuracies\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print(f'K-Nearest Neighbors Accuracy: {accuracy_knn}')\n",
    "\n",
    "# Plot comparison of ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print classification reports for both models\n",
    "print('Classification Report - Logistic Regression:')\n",
    "print(class_report_logistic)\n",
    "print('Classification Report - K-Nearest Neighbors:')\n",
    "print(class_report_knn)\n",
    "\n",
    "# Plot confusion matrices side by side for comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "axes[0].matshow(conf_matrix_logistic, cmap='coolwarm')\n",
    "axes[0].set_title('Confusion Matrix - Logistic Regression')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "axes[1].matshow(conf_matrix_knn, cmap='coolwarm')\n",
    "axes[1].set_title('Confusion Matrix - K-Nearest Neighbors')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Curve\n",
    "Plot the loss curve for the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Curve\n",
    "\n",
    "# Plot the loss curve for the MLPClassifier model\n",
    "plt.figure()\n",
    "plt.plot(logistic_model.loss_curve_, label='Loss Curve')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve - MLPClassifier')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "Calculate and display the accuracy of both models on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "# Calculate and display the accuracy of both models on the test dataset\n",
    "\n",
    "# Print accuracy for Logistic Regression\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "\n",
    "# Print accuracy for K-Nearest Neighbors\n",
    "print(f'K-Nearest Neighbors Accuracy: {accuracy_knn}')\n",
    "\n",
    "# Plot comparison of accuracies\n",
    "models = ['Logistic Regression', 'K-Nearest Neighbors']\n",
    "accuracies = [accuracy_logistic, accuracy_knn]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, accuracies, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "Generate and visualize the confusion matrix for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# Generate confusion matrix for Logistic Regression\n",
    "conf_matrix_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "# Plot confusion matrix for Logistic Regression\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.matshow(conf_matrix_logistic, cmap='coolwarm', fignum=1)\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Generate confusion matrix for K-Nearest Neighbors\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "# Plot confusion matrix for K-Nearest Neighbors\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.matshow(conf_matrix_knn, cmap='coolwarm', fignum=1)\n",
    "plt.title('Confusion Matrix - K-Nearest Neighbors')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "Calculate and display the precision and recall for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision and Recall\n",
    "\n",
    "# Calculate precision and recall for Logistic Regression\n",
    "precision_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)['weighted avg']['precision']\n",
    "recall_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)['weighted avg']['recall']\n",
    "\n",
    "# Calculate precision and recall for K-Nearest Neighbors\n",
    "precision_knn = classification_report(y_test, y_pred_knn, output_dict=True)['weighted avg']['precision']\n",
    "recall_knn = classification_report(y_test, y_pred_knn, output_dict=True)['weighted avg']['recall']\n",
    "\n",
    "# Print precision and recall for both models\n",
    "print(f'Logistic Regression Precision: {precision_logistic}')\n",
    "print(f'Logistic Regression Recall: {recall_logistic}')\n",
    "print(f'K-Nearest Neighbors Precision: {precision_knn}')\n",
    "print(f'K-Nearest Neighbors Recall: {recall_knn}')\n",
    "\n",
    "# Plot comparison of precision and recall\n",
    "models = ['Logistic Regression', 'K-Nearest Neighbors']\n",
    "precisions = [precision_logistic, precision_knn]\n",
    "recalls = [recall_logistic, recall_knn]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, precisions, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Comparison of Model Precisions')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, recalls, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Comparison of Model Recalls')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC and AUC Graph\n",
    "Plot the ROC curve and calculate the AUC for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC and AUC Graph\n",
    "\n",
    "# Plot ROC curve for Logistic Regression\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for K-Nearest Neighbors\n",
    "plt.figure()\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - K-Nearest Neighbors')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison of ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare and Visualize Results\n",
    "Compare the performance of the logistic regression and KNN models and visualize which algorithm performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare and Visualize Results\n",
    "\n",
    "# Print comparison of accuracies\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print(f'K-Nearest Neighbors Accuracy: {accuracy_knn}')\n",
    "\n",
    "# Plot comparison of ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print classification reports for both models\n",
    "print('Classification Report - Logistic Regression:')\n",
    "print(class_report_logistic)\n",
    "print('Classification Report - K-Nearest Neighbors:')\n",
    "print(class_report_knn)\n",
    "\n",
    "# Plot confusion matrices side by side for comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "axes[0].matshow(conf_matrix_logistic, cmap='coolwarm')\n",
    "axes[0].set_title('Confusion Matrix - Logistic Regression')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "axes[1].matshow(conf_matrix_knn, cmap='coolwarm')\n",
    "axes[1].set_title('Confusion Matrix - K-Nearest Neighbors')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot the loss curve for the logistic regression model\n",
    "# plt.figure()\n",
    "# plt.plot(logistic_model.loss_curve_, label='Loss Curve')\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss Curve - Logistic Regression')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Calculate and display the accuracy of both models on the test dataset\n",
    "\n",
    "# Print accuracy for Logistic Regression\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "\n",
    "# Print accuracy for K-Nearest Neighbors\n",
    "print(f'K-Nearest Neighbors Accuracy: {accuracy_knn}')\n",
    "\n",
    "# Plot comparison of accuracies\n",
    "models = ['Logistic Regression', 'K-Nearest Neighbors']\n",
    "accuracies = [accuracy_logistic, accuracy_knn]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, accuracies, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n",
    "# Calculate precision and recall for Logistic Regression\n",
    "precision_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)['weighted avg']['precision']\n",
    "recall_logistic = classification_report(y_test, y_pred_logistic, output_dict=True)['weighted avg']['recall']\n",
    "\n",
    "# Calculate precision and recall for K-Nearest Neighbors\n",
    "precision_knn = classification_report(y_test, y_pred_knn, output_dict=True)['weighted avg']['precision']\n",
    "recall_knn = classification_report(y_test, y_pred_knn, output_dict=True)['weighted avg']['recall']\n",
    "\n",
    "# Print precision and recall for both models\n",
    "print(f'Logistic Regression Precision: {precision_logistic}')\n",
    "print(f'Logistic Regression Recall: {recall_logistic}')\n",
    "print(f'K-Nearest Neighbors Precision: {precision_knn}')\n",
    "print(f'K-Nearest Neighbors Recall: {recall_knn}')\n",
    "\n",
    "# Plot comparison of precision and recall\n",
    "models = ['Logistic Regression', 'K-Nearest Neighbors']\n",
    "precisions = [precision_logistic, precision_knn]\n",
    "recalls = [recall_logistic, recall_knn]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(models, precisions, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Comparison of Model Precisions')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(models, recalls, color=['blue', 'orange'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Comparison of Model Recalls')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for Logistic Regression\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Logistic Regression')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve for K-Nearest Neighbors\n",
    "plt.figure()\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - K-Nearest Neighbors')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot comparison of ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr_logistic, tpr_logistic, color='darkorange', lw=2, label=f'Logistic Regression (area = {roc_auc_logistic:.2f})')\n",
    "plt.plot(fpr_knn, tpr_knn, color='blue', lw=2, label=f'K-Nearest Neighbors (area = {roc_auc_knn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
